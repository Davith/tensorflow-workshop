## Առաջադրանք 3: Training a trivial model

### Քայլ 1:
Ենթադրիր որ չգիտենք կշռի արժեքը։ Բայց գիտենք բազմապատկման արտադրյալը։ Այլ կերպ ասած, գիտենք որ մեր մոդելը երբ ստանում է 3.2 input, այն վերադարձնում է 10.0. Սահմանիր անփոփոխ թենզոր 10.0 արժեքով և վերագրիր **output_**-ին։

### Քայլ 2:
Պետք է նպատակային (կամ կորստի) ֆունկցիա սահմանենք։ Այն նկարագրում է թե ինչքան հեռու է մեր գուշակած արտադրյալը հայտնի պատասխանից։ Հաջորդ քայլերում կփոփոխենք կշռի արժեքը (սկզբնարժեք, 2.0) որպեսզի ստանանք հայտնի պատասկանը (10.0)։ Նպատակային ֆունկցիան կսահմանենք այսպես.

**loss = (output - output_)<sup>2</sup>**

### Քայլ 3:
Հիմա պիտի համակարգչին սովորեցնենք կշռի ճիշտ արժեքը։ Ստեղծիր gradient descent օպտիմիզատոր ու որպես կոնստրուկտորի learning rate պարամետր օգտարծիր 0.025։ Օբյեկտը վերագրիր **optimizer**-ին ([documentation](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)).

### Քայլ 4:
Կանչիր օպտիմիզատորի minimize ֆունկցիան, որը կստեղծի գործողություն։ Հաջորդ քայլում այս գործողությունը կօգտակործենք որ կշիռը սովորեցնենք ([documentation](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer#minimize))։ Գործողությունը վերագրիր **train_step**-ին.

### Քայլ 5:
Ցիկլով 20 անգամ կատարիր ուսուցման քայլը։ Կարող ես օգտագործել Python-ի range ֆունկցիան ([documentation](https://docs.python.org/2/library/functions.html#range)). Ցիկլի ամեն քայլին, տպիր այս երեք արժեքները։
* քայլը (i.e., 0, 1, 2, 3, 4)
* **weight**-ի արժեքը
* **output**-ի արժեքը

### Քայլ 6:
Քա՞նի քայլ է պետք որ հասնենք ճիշտ կշռին (10 / 3.2 = **3.125**)?