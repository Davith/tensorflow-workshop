## Առաջադրանք 4: Կարգավորում և ստուգոմ

**Ցանցը չունի տվյալներ։ Ամեն անգամ session.run() անելիս, պիտի մտածենք տվյալներ պետք է մուտքագրենք feed_dict արգումենտով թե ոչ։**

### Քայլ 1:
Նորմալիզացված գնահատականները համեմատի գուշակած գնահատականներին։ Թվերը մո՞տ են իրար թե՞ ոչ։

### Քայլ 2:
Կորուստի (loss) արժեքը ի՞նչ է։

### Քայլ 3:
Մի քիչ կարգավորենք մեր ցանցը։ Հետևյալ պարամետրները կարող ենք փոխենք որ բարելավենք մեր մոդելը։ Այս տեսակի պարամետրները կոչվում են hyper-parameter։
* Թաքնված շերտի նեյրոնների քանակը
* Variable-ների սկզբնական արժեքները (tf.zeros, tf.random_normal, կամ մի ուրիշ ձև բաշխված թվեր)։
* Gradient descent-ի ուսուցման քայլի չափը (learning rate)
* GradientDescentOptimizer-ի փոխարեն կարող ես օգտագործել մի ուրիշ օպտիմիզատոր ([documentation](https://www.tensorflow.org/api_guides/python/train)).
* Քայլերի քանակը. 1000 քայլը բավարա՞ր է։ Ինչքա՞ն ժամ է տեվում 10000 քայլը կատարել։

### Նշում:
Ի՞նչ խնդիրներ ունի այս ստուգման մեթոդը։ Ստուգման համար օգտագործում ենք նույն տվյալները որ օգտագործել էինք ուսուցման ընթացքում։ Պարզ չի՞ որ մեր մոդելը լավ կաշխատի։ Մեքենայական ուսուցման մեջ շատ լուրջ խնդիր է սա։ Պիտի տվյալները բաժանենք երկու կամ երեք մասի որ կարողանանք անկախ ձևով ուսուցանենք ու ստուգման փուլերի ենթարկենք մեր մոդելը։

### Քայլ 4:
Տվյալները կիսի երկու մասի (ամեն մեկում պահի 5 օրինակ). Մեկը օգտագործի ուսուման համար իսկ մյուսը ստուգման համար։ Կորուստը ինչքա՞ն է երբ ուսուցման տվյալներն ես օգտագործում։ Իսկ ինչքա՞ն է երբ ստուգման տվյալներն ես օգտագործում։

### Քայլ 5:
Մոդելը օգտագործի մի նոր իրավիճակում որոշում կայացնելու նպատակով։ Օրինակ, ենթադրենք ժամը 23:00-ն է ու վաղը ժամը 08:00-ին քննություն պիտի հանձնես, բայց դեռ չես սկսել պարապել քննության համար։ Ի՞նչ կանես որ լավագույն արդյունքը ստանաս։